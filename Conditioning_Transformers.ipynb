{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conditioning Transformers",
      "provenance": [],
      "authorship_tag": "ABX9TyP2DV02kxkEsQPxm5U1ZoeA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacobFV/AGI/blob/master/Conditioning_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvLI6b23w_Mc"
      },
      "source": [
        "# Conditioning Transformers\n",
        "\n",
        "Providing more conditioning gives more control. This principle might be observed in neuron firing, desicion theory, and process control.\n",
        "\n",
        "Go to Runtime &rarr; Run all (`Ctrl.+F9`) to experiment yourself. Have fun! &#128522;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3P8iX9DyVfu"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Essentials but not the point of research"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_JRDFN6w6lk",
        "outputId": "5cb55c8e-edac-465d-97e9-6d0640ee343f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "\n",
        "import tensorflow as tf\n",
        "import transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-tffp1yf3\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-tffp1yf3\n",
            "Requirement already satisfied (use --upgrade to upgrade): transformers==2.9.1 from git+https://github.com/huggingface/transformers in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (1.18.4)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.1.90)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.0.43)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (0.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.9.1-cp36-none-any.whl size=652120 sha256=98c783f4edbf0f1a45c982d4bb884fe363cffbacd0c9db54f65a1d6e49198e65\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fmjddmul/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kUoK8DHjsgb"
      },
      "source": [
        "import logging\n",
        "logging.getLogger('transformers.tokenization_utils').setLevel(logging.ERROR)\n",
        "logging.getLogger('transformers.tokenization_utils').disabled = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imk87kr9iA5s"
      },
      "source": [
        "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
        "transformer = transformers.TFGPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDE-xpudxyd8"
      },
      "source": [
        "def speak(text):\n",
        "    inp_tokens = tokenizer.encode(text, return_tensors='tf')\n",
        "    out_tokens = transformer.generate(\n",
        "        inp_tokens,\n",
        "        max_length=50,\n",
        "        top_k=50,\n",
        "        top_p=0.7,\n",
        "        do_sample=True,\n",
        "        temperature=0.75,\n",
        "        repetition_penalty=10)\n",
        "    return tokenizer.decode(out_tokens[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrd9J-N41tCf"
      },
      "source": [
        "## Experiment\n",
        "\n",
        "I predict that sentences will appear more similar as conditioning length increases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIwql8GR0B77"
      },
      "source": [
        "def experiment(text):\n",
        "    \"\"\"condition gpt-2 generation on progressively longer starting sequences\n",
        "    args:\n",
        "        text: string language input\n",
        "    returns:\n",
        "        gpt-2 outputs\n",
        "    \"\"\"\n",
        "\n",
        "    words = text.split(' ')\n",
        "    for conditioning_len, _ in enumerate(words, start=1):\n",
        "        conditioning_seq = ' '.join(words[0:conditioning_len])\n",
        "        print('='*32+'\\r',f'{conditioning_len}:', speak(conditioning_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbn-5Yrs2Dgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "4758d9b5-a82d-45ca-897c-5a087106e4bf"
      },
      "source": [
        "experiment('AI engineering demands a rigorous examination of every variable involved.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 1: AI and a few others, who are also involved in the project.\n",
            "A lot of what we do here is not just about making money; it's trying to make sure that you get things done.\"<|endoftext|>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 2: AI engineering, and a number of other projects.\n",
            "It is not clear whether the company will take on any additional commitments in its current financial year or if it has already begun to pay down debt with interest rates that are likely lower than those currently scheduled\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 3: AI engineering demands a large number of workers, and so the problem is that there are few people who can do this job. It's not easy to get hired for it,\" says Bhattacharya Rao (retd), an engineer from New Delhi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 4: AI engineering demands a new way of thinking about the future.\n",
            "\n",
            "\n",
            "<|endoftext|>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 5: AI engineering demands a rigorous, scientific approach to building the next generation of autonomous vehicles. The company's new robot-based prototype is designed to be able \"to drive itself on its own,\" says Richard DeGroot at Carnegie Mellon University in Pittsburgh and\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 6: AI engineering demands a rigorous examination of the system, and it is essential that we provide an adequate background on its development.\n",
            "The company has been in business since 1985 as part-owner/operator for over 20 years (in addition to being one or\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 7: AI engineering demands a rigorous examination of the technical aspects and use cases. The objective is to assess whether there are any significant problems with each project that need addressing in order for it be considered as an appropriate solution, or if they could have been avoided altogether\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 8: AI engineering demands a rigorous examination of every aspect, including the design and construction process. The work is done by experts from several disciplines: engineers with experience in designing large scale applications; computer scientists who are involved primarily to understand systems architecture such as hardware acceleration\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 9: AI engineering demands a rigorous examination of every variable in the design and construction process, from structural details to materials. The research team has been working on this for years with some success since its inception by using multiple different techniques including high-speed mechanical analysis (\n",
            " 10: AI engineering demands a rigorous examination of every variable involved. It is important to note that the only way for us (or any other person) or anyone else in our team, who has ever been trained by someone with this kind background and experience on their\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7khUEX7oj8Sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "669f2aaa-60ba-4a5e-a5e5-c1ceda42d399"
      },
      "source": [
        "experiment('Old McDonald had a farm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 1: Old, a man who lives in the neighborhood and has been living there for more than three years.\n",
            "\n",
            "\n",
            " (Photo: Facebook) Story Highlights The house was on fire as of Tuesday morning; it's now down to one story at Stoney Creek\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 2: Old McDonald's is still in business. The chain has closed its doors to customers since May, and it will be shuttered by next year after a court battle over the company buying out some of their stores for $2 billion last month.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================\r 3: Old McDonald had to go, and I didn't know what else.\n",
            "The next morning at the hospital was a big surprise: The first thing he saw when they arrived on scene were his eyes! They looked like black holes in space â€“ with only\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 4: Old McDonald had a good run, but it was his last chance to get on the field. He got hurt and missed all of 2011 with an ankle injury that cost him time at times in 2012 before he played for Cleveland's second team this year as\n",
            " 5: Old McDonald had a farm in North Carolina. He was an avid farmer and used to bring his chickens from the fields down, so he always brought them home with him for dinner or just when we were on our way back out of town,\" she said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YjdDrL2oPO1"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "Being a random machine, I cannot precisely predict the transformer's output. However, the next generated token has high mutual information with previous tokens. If I exercise more control over the previous tokens, then I exercise control ove the following tokens. This is control by narrowing options, as reasonable conclusions decrease in set size with increase priors. Finally, this is comparable to the behavior exhibited in intelligent beings. Although internal dynamics are usually unknown, their predicted behavior is further refined with time. Like gpt-2, longtime friends can even model each other's sentences!"
      ]
    }
  ]
}